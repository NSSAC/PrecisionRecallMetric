{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code and data is simplified to fit within upload requirements (50 MB). Full code and data can be found on our GitHub.\n",
        "\n",
        "Overview of Code:\n",
        "- Setup: Imports and required installations\n",
        "- Metric Functions: Functions following metric definitions and feature extraction\n",
        "- Human Correlation: Perform experiment to test metrics' correlation with human judgement. Note that for small sample sizes (n=10), Density performs properly; however, for the full dataset (n=100000), we see the opposite effect.\n",
        "- Mode Shrinkage Test: Perform experiment to test the impact of increasing classifer-free guidance parameter (CFG), i.e. decreasing generative output diversity while increasing fidelity\n",
        "- Mode Drop Test: Gradually drop modes to test recall measures sensitivity\n",
        "- Additional Experiments: Experiments shown in the appendix: Density metric behavior with increasing samples + memorized image PCE scores"
      ],
      "metadata": {
        "id": "mLWdMY4PUtdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "HSaQHROrDaaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install frechetdist xformers diffusers timm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hMwWDhw19uua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyNDTyNL5GZe"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.nn.functional import interpolate\n",
        "\n",
        "from diffusion import create_diffusion\n",
        "from diffusers.models import AutoencoderKL\n",
        "from download import find_model\n",
        "from models import DiT_models\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "from numpy import pi\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from scipy import linalg\n",
        "from scipy.special import digamma, gamma, loggamma\n",
        "from scipy.linalg import sqrtm\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors, KDTree\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import xformers\n",
        "from collections import defaultdict, Counter\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default matplotlib parameters used\n",
        "plt.rcParams.update({\n",
        "    'font.size': 24,\n",
        "    'axes.labelsize': 26,\n",
        "    'xtick.labelsize': 15,\n",
        "    'ytick.labelsize': 17,\n",
        "    'legend.fontsize': 24,\n",
        "    'axes.titlesize': 24,\n",
        "    'lines.linewidth': 5,\n",
        "    'lines.markersize': 11,\n",
        "    'legend.handlelength': 2,\n",
        "    'errorbar.capsize': 7,\n",
        "    'lines.markeredgewidth': 3,\n",
        "    'font.family': 'sans-serif',\n",
        "    'font.sans-serif': 'DejaVu Sans'\n",
        "})"
      ],
      "metadata": {
        "id": "8HgL7yGDUTYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image pre-processing\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "])"
      ],
      "metadata": {
        "id": "C_15oNEu58da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "DQizwdycJKXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction using DinoV2 encoder\n",
        "def extract_and_save_features(image_dir, file_name, transform):\n",
        "    gen_dataset = ImageFolder(image_dir, transform=transform)\n",
        "    gen_loader = DataLoader(gen_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
        "    model.eval()\n",
        "    model.cuda()\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    print(\"DOING \", file_name)\n",
        "    def extract_features(loader, model):\n",
        "        features = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, _ in tqdm(loader, desc='Extracting Features', leave=True):\n",
        "                inputs = inputs.cuda()\n",
        "                outputs = model(inputs)\n",
        "                features.append(outputs.cpu().numpy())\n",
        "        return np.concatenate(features, axis=0)\n",
        "\n",
        "    gen_features = extract_features(gen_loader, model)\n",
        "\n",
        "    np.save(file_name, gen_features)"
      ],
      "metadata": {
        "id": "ugqFjB4X6RDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For a subset of models trained on ImageNet, extract features\n",
        "source_directories = [\n",
        "    'train',\n",
        "    #'rq',\n",
        "    #'styleganxl',\n",
        "    #'ADM',\n",
        "    #'ADMG',\n",
        "    'ADMG-ADMU',\n",
        "    #'biggan',\n",
        "    #'dit',\n",
        "    #'gigagan',\n",
        "    #d'ldm'\n",
        "]\n",
        "\n",
        "for base_name in source_directories:\n",
        "    source_dir = f'images/imagenet-{base_name}'\n",
        "    file_name = os.path.join(os.getcwd(), f'output/imagenet-{base_name}_features.npy')\n",
        "    extract_and_save_features(source_dir, file_name, transform)"
      ],
      "metadata": {
        "id": "Y89AUdvkPhKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For a subset of models trained on CIFAR10, extract features\n",
        "source_directories = [\n",
        "    'train',\n",
        "    #'ACGAN-Mod',\n",
        "    #'BigGAN-Deep',\n",
        "    #'iDDPM-DDIM',\n",
        "    'LOGAN',\n",
        "    #'LSGM-ODE',\n",
        "    #'MHGAN',\n",
        "    #'NVAE',\n",
        "    'PFGMPP',\n",
        "    #'ReACGAN',\n",
        "    #'RESFLOW',\n",
        "    'StyleGAN2-ada',\n",
        "    #'WGAN-GP',\n",
        "    #'StyleGAN-XL'\n",
        "]\n",
        "\n",
        "for base_name in source_directories:\n",
        "    source_dir = f'images/cifar10-{base_name}'\n",
        "    file_name = os.path.join(os.getcwd(), f'output/cifar10-{base_name}_features.npy')\n",
        "    extract_and_save_features(source_dir, file_name, transform)"
      ],
      "metadata": {
        "id": "SQeKIO_qPW2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric Functions"
      ],
      "metadata": {
        "id": "ga2dAN9HJQQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computes the Frechet Distance between two datasets rep. by multivariate normal distributions\n",
        "def compute_fd(reps1, reps2, eps=1e-6):\n",
        "    mu1, sigma1 = np.mean(reps1, axis=0), np.cov(reps1, rowvar=False)\n",
        "    mu2, sigma2 = np.mean(reps2, axis=0), np.cov(reps2, rowvar=False)\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "    try:\n",
        "        covmean = sqrtm(sigma1.dot(sigma2))\n",
        "        if np.iscomplexobj(covmean):\n",
        "            covmean = covmean.real\n",
        "    except ValueError:\n",
        "        covmean = sqrtm(sigma1 + eps * np.eye(sigma1.shape[0])).dot(sqrtm(sigma2 + eps * np.eye(sigma2.shape[0])))\n",
        "        covmean = covmean.real\n",
        "\n",
        "    tr_covmean = np.trace(covmean)\n",
        "    frechet_distance = np.dot(diff, diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
        "    return frechet_distance"
      ],
      "metadata": {
        "id": "UQgW19E9_TuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to calculate our metric defined in Section 5, precision cross-entropy, recall cross-entropy, and recall-entropy\n",
        "\n",
        "# helper function\n",
        "def volume_of_unit_ball_log(d):\n",
        "    # Use Stirling's approximation directly in log form\n",
        "    d_over_2 = d / 2\n",
        "    return d_over_2 * np.log(pi) - (loggamma(d_over_2 + 1))\n",
        "\n",
        "# Calculate cross entropy\n",
        "def cross_entropy(N, M, k, nu_k, d):\n",
        "    psi_k = digamma(k)\n",
        "\n",
        "    c_bar = volume_of_unit_ball_log(d)\n",
        "\n",
        "    inner_term = np.log(M) - psi_k + c_bar + d*np.log(nu_k)\n",
        "    entropy_estimate = (1 / N) * np.sum(inner_term)\n",
        "\n",
        "    return entropy_estimate\n",
        "\n",
        "# Calculate entropy\n",
        "def entropy(N, k, rho_k, d):\n",
        "    psi_k = digamma(k)\n",
        "\n",
        "    c_bar = volume_of_unit_ball_log(d)\n",
        "\n",
        "    inner_term = np.log(N-1) - psi_k + c_bar + d*np.log(rho_k)\n",
        "    entropy_estimate = (1 / N) * np.sum(inner_term)\n",
        "\n",
        "    return entropy_estimate"
      ],
      "metadata": {
        "id": "grz4mKlcDJ9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate all knn metrics analyzed\n",
        "\n",
        "def calc_precision(dist_R, dist_RG_pairs, M):\n",
        "    radii_R = dist_R[:, -1]  # dist to the real k-th neighbor of real points\n",
        "\n",
        "    # for every real point, check if at least 1 gen point within radius\n",
        "    G_in_radius = (dist_RG_pairs <= radii_R[:, np.newaxis])\n",
        "    precision_count = np.sum(np.any(G_in_radius, axis=0))\n",
        "\n",
        "    return precision_count / M\n",
        "\n",
        "def calc_density(dist_R, dist_RG_pairs, k, M):\n",
        "    radii_R = dist_R[:, -1]\n",
        "\n",
        "    # for every real point, count # of gen points within radius\n",
        "    G_in_radius = (dist_RG_pairs <= radii_R[:, np.newaxis])\n",
        "    density_count = np.sum(G_in_radius) / k\n",
        "\n",
        "    return density_count / M\n",
        "\n",
        "def calc_coverage(dist_R, dist_RG_pairs):\n",
        "    radii_R = dist_R[:, -1]\n",
        "\n",
        "    G_in_radius = (dist_RG_pairs <= radii_R[:, np.newaxis])\n",
        "    R_contains_G = np.any(G_in_radius, axis=1)\n",
        "\n",
        "    return np.mean(R_contains_G)\n",
        "\n",
        "def calc_PC(G, nbrs_G, nbrs_R, M, k, C):\n",
        "    k_prime = C * k\n",
        "    dist_G, _ = nbrs_G.kneighbors(G, k_prime+1)\n",
        "    radii_G = dist_G[:, -1]\n",
        "\n",
        "    precision_count = 0\n",
        "    dist_RG, _ = nbrs_R.kneighbors(G, k)\n",
        "    R_in_radius = (dist_RG[:, -1] <= radii_G)\n",
        "    precision_count += np.sum(R_in_radius)\n",
        "\n",
        "    return precision_count / M\n",
        "\n",
        "# k = 2 for representative dataset, used k=5 for full dataset\n",
        "def calculate_realism_scores(R, G, k = 2, C = 3):\n",
        "    prc_k = C * k\n",
        "\n",
        "    # set up nearest neighbor graphs\n",
        "    nbrs_R = NearestNeighbors(n_neighbors=prc_k+1, algorithm='auto', n_jobs=-1).fit(R) # ignore first neighbor (itself)\n",
        "    dist_R, _ = nbrs_R.kneighbors(R, k+1)\n",
        "\n",
        "    nbrs_G = NearestNeighbors(n_neighbors=prc_k+1, algorithm='auto', n_jobs=-1).fit(G)\n",
        "    dist_G, _ = nbrs_G.kneighbors(G, k+1)\n",
        "\n",
        "    dist_RG_pairs = pairwise_distances(R, G, n_jobs=-1)\n",
        "    dist_GR_pairs = pairwise_distances(G, R, n_jobs=-1)\n",
        "\n",
        "    dist_RG, _ = nbrs_G.kneighbors(R, k+1)\n",
        "    dist_GR, _ = nbrs_R.kneighbors(G, k+1)\n",
        "\n",
        "    # density + coverage (section 4)\n",
        "    density = calc_density(dist_R, dist_RG_pairs, k, len(G))\n",
        "    coverage = calc_coverage(dist_R, dist_RG_pairs)\n",
        "\n",
        "    # prc (section 4)\n",
        "    pc = calc_PC(G, nbrs_G, nbrs_R, len(G), k, 3)\n",
        "    rc = calc_PC(R, nbrs_R, nbrs_G, len(R), k, 3) # rc is symmetric to pc\n",
        "\n",
        "    # fd\n",
        "    fd = compute_fd(R, G)\n",
        "\n",
        "    # information theoretic score (section 5)\n",
        "    ce_gr = cross_entropy(len(G), len(R), k, dist_GR[:, k-1], len(R[0]))\n",
        "    ce_rg = cross_entropy(len(R), len(G), k, dist_RG[:, k-1], len(R[0]))\n",
        "    e_r = entropy(len(R), k, dist_R[:, k], len(R[0]))\n",
        "    e_g = entropy(len(G), k, dist_G[:, k], len(G[0]))\n",
        "\n",
        "    return fd, density, coverage, pc, rc, ce_gr-e_r, ce_rg-e_r, e_g-e_r\n"
      ],
      "metadata": {
        "id": "Puc_mJh3DL8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric Analysis"
      ],
      "metadata": {
        "id": "5PZzfRbwDYHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation coefficient between metrics and human error rate and print correlation matrix\n",
        "\n",
        "def calc_human_corr(real_features, model_features, human_ranking):\n",
        "    scores_FD = {}\n",
        "    scores_PCE = {}\n",
        "    scores_RCE = {}\n",
        "    scores_RE = {}\n",
        "    scores_density = {}\n",
        "    scores_coverage = {}\n",
        "    scores_PC = {}\n",
        "    scores_RC = {}\n",
        "\n",
        "    for model_name, features in model_features.items():\n",
        "        print(model_name)\n",
        "        fd, density, coverage, pc, rc, pce, rce, re = calculate_realism_scores(real_features, features)\n",
        "        scores_FD[model_name] = fd\n",
        "        scores_density[model_name] = density\n",
        "        scores_coverage[model_name] = coverage\n",
        "        scores_PC[model_name] = pc\n",
        "        scores_RC[model_name] = rc\n",
        "        scores_PCE[model_name] = pce\n",
        "        scores_RCE[model_name] = rce\n",
        "        scores_RE[model_name] = re\n",
        "        print(\"done\")\n",
        "\n",
        "    # rank\n",
        "    rankings_PCE = sorted(scores_PCE.items(), key=lambda x: x[1])\n",
        "    rankings_RCE = sorted(scores_RCE.items(), key=lambda x: x[1])\n",
        "    rankings_RE = sorted(scores_RE.items(), key=lambda x: -x[1])\n",
        "    rankings_FD = sorted(scores_FD.items(), key=lambda x: x[1])\n",
        "    rankings_D = sorted(scores_density.items(), key=lambda x: -x[1])\n",
        "    rankings_C = sorted(scores_coverage.items(), key=lambda x: -x[1])\n",
        "    rankings_PC = sorted(scores_PC.items(), key=lambda x: -x[1])\n",
        "    rankings_RC = sorted(scores_RC.items(), key=lambda x: -x[1])\n",
        "\n",
        "    print(\"Human Ranking (Best to Worst):\")\n",
        "    sorted_human_ranking = sorted(human_ranking.items(), key=lambda item: -item[1])\n",
        "    for rank, (model, score) in enumerate(sorted_human_ranking, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    print(\"\\nModel-Based Rankings:\")\n",
        "\n",
        "    print(\"\\nRankings based on PC Score (Best to Worst):\")\n",
        "    for rank, (model, score) in enumerate(rankings_PC, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    print(\"\\nRankings based on RC Score (Best to Worst):\")\n",
        "    for rank, (model, score) in enumerate(rankings_RC, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    print(\"\\nRankings based on PCE Score (Best to Worst):\")\n",
        "    for rank, (model, score) in enumerate(rankings_PCE, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    print(\"\\nRankings based on RCE Score (Best to Worst):\")\n",
        "    for rank, (model, score) in enumerate(rankings_RCE, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    print(\"\\nRankings based on RE Score (Best to Worst):\")\n",
        "    for rank, (model, score) in enumerate(rankings_RE, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    print(\"\\nRankings based on FD Score (Best to Worst):\")\n",
        "    for rank, (model, score) in enumerate(rankings_FD, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    print(\"\\nRankings based on Density Score (Best to Worst):\")\n",
        "    for rank, (model, score) in enumerate(rankings_D, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    print(\"\\nRankings based on Coverage Score (Best to Worst):\")\n",
        "    for rank, (model, score) in enumerate(rankings_C, start=1):\n",
        "        print(f\"{rank}. {model}: {score}\")\n",
        "\n",
        "    human_ranking_neg = {key: -value for key, value in human_ranking.items()}\n",
        "    scores_density_neg = {key: -value for key, value in scores_density.items()}\n",
        "    scores_coverage_neg = {key: -value for key, value in scores_coverage.items()}\n",
        "    scores_PC_neg = {key: -value for key, value in scores_PC.items()}\n",
        "    scores_RC_neg = {key: -value for key, value in scores_RC.items()}\n",
        "    scores_RE_neg = {key: -value for key, value in scores_RE.items()}\n",
        "\n",
        "    model_names = human_ranking.keys()\n",
        "\n",
        "    def align_scores(scores_dict, model_names):\n",
        "        return [scores_dict[name] for name in model_names]\n",
        "\n",
        "    scores_list_PCE = align_scores(scores_PCE, model_names)\n",
        "    scores_list_RCE = align_scores(scores_RCE, model_names)\n",
        "    scores_list_RE = align_scores(scores_RE_neg, model_names)\n",
        "    scores_list_FD = align_scores(scores_FD, model_names)\n",
        "    scores_list_D = align_scores(scores_density_neg, model_names)\n",
        "    scores_list_C = align_scores(scores_coverage_neg, model_names)\n",
        "    scores_list_PC = align_scores(scores_PC_neg, model_names)\n",
        "    scores_list_RC = align_scores(scores_RC_neg, model_names)\n",
        "    scores_list_human = align_scores(human_ranking_neg, model_names)\n",
        "\n",
        "    # print correlation matrix\n",
        "    scores_matrix = np.array([scores_list_human, scores_list_PC, scores_list_RC, scores_list_PCE, scores_list_RCE, scores_list_RE, scores_list_FD, scores_list_D, scores_list_C])\n",
        "    correlation_matrix = np.corrcoef(scores_matrix)\n",
        "    print(correlation_matrix)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", xticklabels=['Human', 'PC', 'RC', 'PCE', 'RCE', 'RE', 'FD', 'Density', 'Coverage'], yticklabels=['Human', 'PC', 'RC', 'PCE', 'RCE', 'RE', 'FD', 'Density', 'Coverage'])\n",
        "    plt.title(\"Correlation Heatmap between Rankings\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "MgZ9hQS0ND-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Human error rate for sampled generated datasets from Stein et al. (2024)\n",
        "\n",
        "#human_ranking = {'RESFLOW':0.088, 'NVAE':0.1308, 'ACGAN-Mod':0.148, 'WGAN-GP':0.169, 'LOGAN':0.2056, 'ReACGAN':0.335, 'MHGAN':0.336, 'BigGAN-Deep': 0.386, 'StyleGAN2':0.393, 'StyleGAN-XL':0.3988, 'iDDPM-DDIM':0.399, 'PFGMPP':0.4358, 'LSGM-ODE':0.436}\n",
        "human_ranking = {'LOGAN':0.2056, 'StyleGAN2':0.393, 'PFGMPP':0.4358}"
      ],
      "metadata": {
        "id": "7cNk424UH1EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_features = np.load('output/cifar10-train_features.npy')\n",
        "model_features = {\n",
        "    #'ACGAN-Mod': np.load('output/cifar10-ACGAN-Mod_features.npy'),\n",
        "    #'BigGAN-Deep': np.load('output/cifar10-BigGAN-Deep_features.npy'),\n",
        "    #'iDDPM-DDIM': np.load('output/cifar10-iDDPM-DDIM_features.npy'),\n",
        "    'LOGAN': np.load('output/cifar10-LOGAN_features.npy'),\n",
        "    #'LSGM-ODE': np.load('output/cifar10-LSGM-ODE_features.npy'),\n",
        "    #'MHGAN': np.load('output/cifar10-MHGAN_features.npy'),\n",
        "    #'NVAE': np.load('output/cifar10-NVAE_features.npy'),\n",
        "    'PFGMPP': np.load('output/cifar10-PFGMPP_features.npy'),\n",
        "    #'ReACGAN': np.load('output/cifar10-ReACGAN_features.npy'),\n",
        "    #'RESFLOW': np.load('output/cifar10-RESFLOW_features.npy'),\n",
        "    'StyleGAN2': np.load('output/cifar10-StyleGAN2-ada_features.npy'),\n",
        "    #'WGAN-GP': np.load('output/cifar10-WGAN-GP_features.npy'),\n",
        "    #'StyleGAN-XL': np.load('output/cifar10-StyleGAN-XL_features.npy')\n",
        "}"
      ],
      "metadata": {
        "id": "dPToEnn6OS0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_human_corr(real_features, model_features, human_ranking)"
      ],
      "metadata": {
        "id": "HBudm_plOZbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mode Shrinkage Test"
      ],
      "metadata": {
        "id": "EEtc-aUvSOGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Originally, 15 class labels for 2 sets are randomly generated without replacement from 0-999\n",
        "# Simplified code presets classes to fit representative dataset\n",
        "class_labels = [319, 121, 299, 32, 269]"
      ],
      "metadata": {
        "id": "bBCqAJ5YSSE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code adapted from official DiT model documentation to run model to generate images at varying CFG parameters\n",
        "\n",
        "def run_model(class_labels):\n",
        "    # configuration\n",
        "    device = \"cuda\"\n",
        "    model_choice = \"DiT-XL/2\"\n",
        "    vae_choice = \"mse\"\n",
        "    image_size = 256\n",
        "    num_classes = 1000\n",
        "    num_sampling_steps = 250\n",
        "    batch_number = 1\n",
        "    ckpt_path = None\n",
        "\n",
        "    # setup\n",
        "    if ckpt_path is None:\n",
        "        assert model_choice == \"DiT-XL/2\", \"Only DiT-XL/2 models are available for auto-download.\"\n",
        "        assert image_size in [256, 512]\n",
        "        assert num_classes == 1000\n",
        "\n",
        "    latent_size = image_size // 8\n",
        "    model = DiT_models[model_choice](input_size=latent_size, num_classes=num_classes).to(device)\n",
        "    state_dict = find_model(f\"DiT-XL-2-{image_size}x{image_size}.pt\")\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    diffusion = create_diffusion(str(num_sampling_steps))\n",
        "    vae = AutoencoderKL.from_pretrained(f\"stabilityai/sd-vae-ft-{vae_choice}\").to(device)\n",
        "\n",
        "    # generation loop\n",
        "    cfg_scales = [1.5, 3.0, 4.5, 6.0]\n",
        "    samples_per_class = 10\n",
        "\n",
        "    for cfg_scale in cfg_scales:\n",
        "        for class_label in class_labels:\n",
        "            print(f\"Generating {samples_per_class} samples for class {class_label} with CFG scale: {cfg_scale}\")\n",
        "            output_dir = f\"./output/cfg_{cfg_scale}/{batch_number}/{class_label}\"\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "            batch_size = 10\n",
        "            num_batches = (samples_per_class + batch_size - 1) // batch_size\n",
        "\n",
        "            for batch_index in range(num_batches):\n",
        "                current_batch_size = min(batch_size, samples_per_class - batch_index * batch_size)\n",
        "                z = torch.randn(current_batch_size, 4, latent_size, latent_size, device=device)\n",
        "                y = torch.full((current_batch_size,), class_label, device=device)\n",
        "                z = torch.cat([z, z], 0)\n",
        "                y_null = torch.full((current_batch_size,), 1000, device=device)\n",
        "                y = torch.cat([y, y_null], 0)\n",
        "\n",
        "                model_kwargs = {'y': y, 'cfg_scale': cfg_scale}\n",
        "                samples = diffusion.p_sample_loop(model.forward_with_cfg, z.shape, z, clip_denoised=False, model_kwargs=model_kwargs, progress=True, device=device)\n",
        "                samples, _ = samples.chunk(2, dim=0)\n",
        "                decoded_samples = vae.decode(samples / 0.18215).sample\n",
        "\n",
        "                for i in range(current_batch_size):\n",
        "                    sample_filename = os.path.join(output_dir, f\"sample_{batch_index * batch_size + i + 1}.png\")\n",
        "                    save_image(decoded_samples[i], sample_filename, normalize=True, value_range=(-1, 1))\n",
        "\n",
        "run_model(class_labels)"
      ],
      "metadata": {
        "id": "AWEY2J11xQgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features for previously generated images\n",
        "source_directories = [\n",
        "    'cfg_1.5',\n",
        "    'cfg_3.0',\n",
        "    'cfg_4.5',\n",
        "    'cfg_6.0',\n",
        "]\n",
        "\n",
        "for source_dir in source_directories:\n",
        "    file_name = os.path.join(os.getcwd(), f'./output/{source_dir}_features.npy')\n",
        "    full_source_dir = os.path.expanduser(f'./output/{source_dir}/1')\n",
        "    extract_and_save_features(full_source_dir, file_name, transform)"
      ],
      "metadata": {
        "id": "Bj_BD5aoT3Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for all levels of CFG\n",
        "def run_metrics_all():\n",
        "    metrics = ['FD', 'Density', 'Coverage', 'PC', 'RC', 'PCE', 'RCE', 'RE']\n",
        "    data = {\n",
        "        'Run': [],\n",
        "        'Class Set': [],\n",
        "        'CFG': [],\n",
        "        'Metric': [],\n",
        "        'Value': []\n",
        "    }\n",
        "\n",
        "    for batch_number in range(1):  # full code uses 6 batches\n",
        "        class_set = 1\n",
        "        real_features_path = './output/imagenet-train_features.npy' if class_set == 1 else './output/imagenet-train2_features.npy'\n",
        "        real_features = np.load(real_features_path)\n",
        "\n",
        "        model_features = {\n",
        "            '1.5': np.load(f'./output/cfg_1.5_features.npy'),\n",
        "            '3.0': np.load(f'./output/cfg_3.0_features.npy'),\n",
        "            '4.5': np.load(f'./output/cfg_4.5_features.npy'),\n",
        "            '6.0': np.load(f'./output/cfg_6.0_features.npy')\n",
        "        }\n",
        "\n",
        "        for cfg, features in model_features.items():\n",
        "            scores = calculate_realism_scores(real_features, features)\n",
        "            for metric, value in zip(metrics, scores):\n",
        "                print(metric, value)\n",
        "                data['Run'].append(batch_number)\n",
        "                data['Class Set'].append(class_set)\n",
        "                data['CFG'].append(cfg)\n",
        "                data['Metric'].append(metric)\n",
        "                data['Value'].append(value)\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df_results = run_metrics_all()"
      ],
      "metadata": {
        "id": "x3a4FyViVS0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting functions\n",
        "\n",
        "def plot_d_c(data, ax):\n",
        "    metrics = ['Density', 'Coverage']\n",
        "    cfgs = sorted(data['CFG'].unique(), key=float)\n",
        "    class_sets = data['Class Set'].unique()\n",
        "\n",
        "    # define marker styles for metrics\n",
        "    markers = {\n",
        "        'Density': ('x', 10),  # 'x' marker with size 10\n",
        "        'Coverage': ('D', 5)   # Diamond marker with size 5\n",
        "    }\n",
        "\n",
        "    # define style combinations for each metric and class set pair\n",
        "    color_styles = {\n",
        "        ('Density', 1): {'color': 'mediumblue', 'line': '-', 'dashes': [10, 10]},\n",
        "        #('Density', 2): {'color': 'mediumblue', 'line': '--', 'dashes': [10, 10]},\n",
        "        ('Coverage', 1): {'color': 'orange', 'line': '-', 'dashes': [10, 10]},\n",
        "        #('Coverage', 2): {'color': 'orange', 'line': '--', 'dashes': [10, 10]}\n",
        "    }\n",
        "\n",
        "    for metric in metrics:\n",
        "        for class_set in class_sets:\n",
        "            subset = data[(data['Metric'] == metric) & (data['Class Set'] == class_set)]\n",
        "            means = subset.groupby('CFG')['Value'].mean()\n",
        "            stds = subset.groupby('CFG')['Value'].std()\n",
        "\n",
        "            # apply color and line style based on metric and class set combination\n",
        "            style = color_styles[(metric, class_set)]\n",
        "            marker, size = markers[metric]\n",
        "            ax.plot(cfgs, means, f\"{style['line']}{marker}\", color=style['color'],\n",
        "                    markersize=size, label=f'{metric} ({class_set})')\n",
        "            #ax.errorbar(cfgs, means, yerr=stds, fmt=f\"{style['line']}{marker}\", color=style['color'],elinewidth=2,\n",
        "            #            markersize=size, label=f'{metric[0]} ({class_set})', capthick=2, ecolor='gray')\n",
        "\n",
        "    ax.set_title('(a) Density and Coverage')\n",
        "    ax.set_xlabel('CFG Scale')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_ylim(bottom=0)\n",
        "    ax.legend(loc='lower left', fontsize=17)\n",
        "    ax.grid(True)\n",
        "\n",
        "def plot_pc_rc(data, ax):\n",
        "    metrics = ['PC', 'RC']\n",
        "    cfgs = sorted(data['CFG'].unique(), key=float)\n",
        "    class_sets = data['Class Set'].unique()\n",
        "\n",
        "    markers = {'PC': ('x', 10), 'RC': ('D', 5)}\n",
        "    color_styles = {\n",
        "        ('PC', 1): {'color': 'mediumblue', 'line': '-', 'dashes': [10, 10]},\n",
        "        #('PC', 2): {'color': 'mediumblue', 'line': '--', 'dashes': [10, 10]},\n",
        "        ('RC', 1): {'color': 'orange', 'line': '-', 'dashes': [10, 10]},\n",
        "        #('RC', 2): {'color': 'orange', 'line': '--', 'dashes': [10, 10]}\n",
        "    }\n",
        "\n",
        "    for metric in metrics:\n",
        "        for class_set in class_sets:\n",
        "            subset = data[(data['Metric'] == metric) & (data['Class Set'] == class_set)]\n",
        "            means = subset.groupby('CFG')['Value'].mean()\n",
        "            stds = subset.groupby('CFG')['Value'].std()\n",
        "\n",
        "            style = color_styles[(metric, class_set)]\n",
        "            marker, size = markers[metric]\n",
        "            ax.plot(cfgs, means, f\"{style['line']}{marker}\", color=style['color'],\n",
        "                    markersize=size, label=f'{metric} ({class_set})')\n",
        "            #ax.errorbar(cfgs, means, yerr=stds, fmt=f\"{style['line']}{marker}\", color=style['color'], elinewidth=2,\n",
        "            #            markersize=size, label=f'{metric} ({class_set})', capthick=2, ecolor='gray')\n",
        "\n",
        "    ax.set_title('(b) Precision and Recall Coverage')\n",
        "    ax.set_xlabel('CFG Scale')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_ylim(0)\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "def plot_re(data, ax):\n",
        "    metrics = ['RE']\n",
        "    cfgs = sorted(data['CFG'].unique(), key=float)\n",
        "    class_sets = data['Class Set'].unique()\n",
        "\n",
        "    markers = {'RE': ('^', 7)}\n",
        "    color_styles = {\n",
        "        ('RE', 1): {'color': 'green', 'line': '-', 'dashes': [10, 10]},\n",
        "        #('RE', 2): {'color': 'green', 'line': '--', 'dashes': [10, 10]}\n",
        "    }\n",
        "\n",
        "    for metric in metrics:\n",
        "        for class_set in class_sets:\n",
        "            subset = data[(data['Metric'] == metric) & (data['Class Set'] == class_set)]\n",
        "            means = subset.groupby('CFG')['Value'].mean()\n",
        "            stds = subset.groupby('CFG')['Value'].std()\n",
        "\n",
        "            style = color_styles[(metric, class_set)]\n",
        "            marker, size = markers[metric]\n",
        "            ax.plot(cfgs, means, f\"{style['line']}{marker}\", color=style['color'],\n",
        "                    markersize=size, label=f'{metric} ({class_set})')\n",
        "            #ax.errorbar(cfgs, means, yerr=stds, fmt=f\"{style['line']}{marker}\", color=style['color'], elinewidth=2,\n",
        "            #            markersize=size, label=f'{metric} ({class_set})', capthick=2, ecolor='gray')\n",
        "\n",
        "    ax.set_title('(d) Recall Entropy')\n",
        "    ax.set_xlabel('CFG Scale')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "def plot_prce(data, ax):\n",
        "    metrics = ['PCE', 'RCE']\n",
        "    cfgs = sorted(data['CFG'].unique(), key=float)\n",
        "    class_sets = data['Class Set'].unique()\n",
        "\n",
        "    markers = {'PCE': ('x', 10), 'RCE': ('D', 5)}\n",
        "    color_styles = {\n",
        "        ('PCE', 1): {'color': 'mediumblue', 'line': '-', 'dashes': [10, 10]},\n",
        "        #('PCE', 2): {'color': 'mediumblue', 'line': '--', 'dashes': [10, 10]},\n",
        "        ('RCE', 1): {'color': 'orange', 'line': '-', 'dashes': [10, 10]},\n",
        "        #('RCE', 2): {'color': 'orange', 'line': '--', 'dashes': [10, 10]}\n",
        "    }\n",
        "\n",
        "    for metric in metrics:\n",
        "        for class_set in class_sets:\n",
        "            subset = data[(data['Metric'] == metric) & (data['Class Set'] == class_set)]\n",
        "            means = subset.groupby('CFG')['Value'].mean()\n",
        "            stds = subset.groupby('CFG')['Value'].std()\n",
        "\n",
        "            style = color_styles[(metric, class_set)]\n",
        "            marker, size = markers[metric]\n",
        "            ax.plot(cfgs, means, f\"{style['line']}{marker}\", color=style['color'],\n",
        "                    markersize=size, label=f'{metric} ({class_set})')\n",
        "            #ax.errorbar(cfgs, means, yerr=stds, fmt=f\"{style['line']}{marker}\", color=style['color'], elinewidth=2,\n",
        "            #            markersize=size, label=f'{metric} ({class_set})', capthick=2, ecolor='gray')\n",
        "\n",
        "    ax.set_title('(c) Precision and Recall Cross-Entropy')\n",
        "    ax.set_xlabel('CFG Scale')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_ylim(bottom=-500)\n",
        "    ax.legend(fontsize=22)\n",
        "    ax.grid(True)\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "plot_d_c(df_results, axs[0, 0])\n",
        "plot_pc_rc(df_results, axs[0, 1])\n",
        "plot_prce(df_results, axs[1, 0])\n",
        "plot_re(df_results, axs[1, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mtLhYmQVV7Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop Test"
      ],
      "metadata": {
        "id": "w-DQVuyeZC0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up generated dataset for mode dropping\n",
        "gen_features = np.load('output/imagenet-ADMG-ADMU_features.npy')\n",
        "print(gen_features.shape)\n",
        "np.save('output/imagenet-ADMG-ADMU_features_5.npy', gen_features)"
      ],
      "metadata": {
        "id": "x4eWh-Fha_fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary for the # of samples per class to aid in dropping\n",
        "def count_samples_per_class(source_dir, transform):\n",
        "    full_dataset = ImageFolder(source_dir, transform=transform)\n",
        "\n",
        "    class_to_idx = full_dataset.class_to_idx\n",
        "    all_classes = list(class_to_idx.keys())\n",
        "\n",
        "    class_counts = {}\n",
        "\n",
        "    for class_name, idx in class_to_idx.items():\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        num_files = len([f for f in os.listdir(class_dir) if f.endswith(('.png'))])\n",
        "        class_counts[class_name] = num_files\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "source_dir= 'images/imagenet-ADMG-ADMU'\n",
        "class_counts = count_samples_per_class(source_dir, transform)"
      ],
      "metadata": {
        "id": "9faz4MvkbTf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mode dropping\n",
        "def drop_random_classes(features, class_counts, classes_to_drop):\n",
        "    expanded_classes = []\n",
        "    for class_label, count in class_counts.items():\n",
        "        expanded_classes.extend([class_label] * count)\n",
        "\n",
        "    expanded_classes = np.array(expanded_classes)\n",
        "\n",
        "    # determine indices to keep\n",
        "    keep_indices = ~np.isin(expanded_classes, classes_to_drop)\n",
        "\n",
        "    # filter the features array\n",
        "    reduced_features = features[keep_indices]\n",
        "\n",
        "    return reduced_features\n",
        "\n",
        "# determine which classes remain and can be dropped\n",
        "def drop(features, class_counts, keep, batch, dropped_classes, num_classes_to_drop=100):\n",
        "    if(len(dropped_classes) == 0):\n",
        "        remaining_classes = [cls for cls in class_counts]\n",
        "    else:\n",
        "        remaining_classes = [cls for cls in class_counts if cls not in dropped_classes]\n",
        "    classes_to_drop = np.random.choice(remaining_classes, num_classes_to_drop, replace=False)\n",
        "    dropped_classes.extend(classes_to_drop)\n",
        "    print(len(dropped_classes))\n",
        "\n",
        "    reduced_features = drop_random_classes(features, class_counts, dropped_classes)\n",
        "    print(reduced_features.shape)\n",
        "    np.save(f'output/imagenet-ADMG-ADMU_features_{keep}_{batch}.npy', reduced_features)\n",
        "    return dropped_classes\n",
        "\n",
        "\n",
        "#keep_num = np.arange(100, 1000, 100).tolist()\n",
        "#keep_num.reverse()\n",
        "keep_num = [4, 3, 2, 1]\n",
        "\n",
        "for batch in range(1): # originally 10 batches\n",
        "    dropped_classes = []\n",
        "    for keep in keep_num:\n",
        "        new_dropped_classes = drop(gen_features, class_counts, keep, batch+1, dropped_classes, 1)\n",
        "        dropped_classes = new_dropped_classes\n"
      ],
      "metadata": {
        "id": "JGTGEw0rbKAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for mode dropping\n",
        "def calc_for_drop(model_name, batch):\n",
        "    real_features = np.load('output/imagenet-train_features.npy')\n",
        "    model_features = {}\n",
        "    num_to_keep = [1, 2, 3, 4]\n",
        "    for keep_num in num_to_keep:\n",
        "        model_features[f'{model_name}_{keep_num}'] = np.load(f'output/imagenet-{model_name}_features_{keep_num}_{batch}.npy')\n",
        "    model_features[f'{model_name}_5'] = np.load(f'output/imagenet-{model_name}_features_5.npy')\n",
        "\n",
        "    scores_FD = {}\n",
        "    scores_PCE = {}\n",
        "    scores_RCE = {}\n",
        "    scores_RE = {}\n",
        "    scores_density = {}\n",
        "    scores_coverage = {}\n",
        "    scores_PC = {}\n",
        "    scores_RC = {}\n",
        "\n",
        "    for model_name, features in model_features.items():\n",
        "        print(model_name)\n",
        "        fd, density, coverage, pc, rc, pce, rce, re = calculate_realism_scores(real_features, features)\n",
        "        scores_FD[model_name] = fd\n",
        "        scores_density[model_name] = density\n",
        "        scores_coverage[model_name] = coverage\n",
        "        scores_PC[model_name] = pc\n",
        "        scores_RC[model_name] = rc\n",
        "        scores_PCE[model_name] = pce\n",
        "        scores_RCE[model_name] = rce\n",
        "        scores_RE[model_name] = re\n",
        "        print(\"done\")\n",
        "\n",
        "    # Dump\n",
        "    with open(f'output/imagenetscores_recall_{batch}.pkl', 'wb') as f:\n",
        "        pickle.dump((scores_FD, scores_density, scores_coverage, scores_PC, scores_RC, scores_PCE, scores_RCE, scores_RE), f)\n"
      ],
      "metadata": {
        "id": "OUfv_bXWZEov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_for_drop('ADMG-ADMU', 1)"
      ],
      "metadata": {
        "id": "oJ2uT-CAu0k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting setup\n",
        "density_scores, coverage_scores, rc_scores, pc_scores = [], [], [], []\n",
        "pce_scores, rce_scores, re_scores, fd_scores = [], [], [], []\n",
        "\n",
        "for i in range(1):\n",
        "    with open(f'output/imagenetscores_recall_{i+1}.pkl', 'rb') as f:\n",
        "        scores = pickle.load(f)\n",
        "        coverage_scores.append(list(np.flip(list(scores[2].values()))))\n",
        "        rc_scores.append(list(np.flip(list(scores[4].values()))))\n",
        "        pc_scores.append(list(np.flip(list(scores[3].values()))))\n",
        "        density_scores.append(list(np.flip(list(scores[1].values()))))\n",
        "        rce_scores.append(list(np.flip(list(scores[6].values()))))\n",
        "        pce_scores.append(list(np.flip(list(scores[5].values()))))\n",
        "        re_scores.append(list(np.flip(list(scores[7].values()))))\n",
        "        fd_scores.append(list(np.flip(list(scores[0].values()))))\n",
        "\n",
        "coverage_scores = np.array(coverage_scores)\n",
        "rc_scores = np.array(rc_scores)\n",
        "pc_scores = np.array(pc_scores)\n",
        "density_scores = np.array(density_scores)\n",
        "rce_scores = np.array(rce_scores)\n",
        "pce_scores = np.array(pce_scores)\n",
        "re_scores = np.array(re_scores)\n",
        "fd_scores = np.array(fd_scores)\n",
        "\n",
        "# calculate means and standard deviations for error bars, not visualized in the simplified code\n",
        "means = {\n",
        "    \"Coverage\": np.mean(coverage_scores, axis=0),\n",
        "    \"RC\": np.mean(rc_scores, axis=0),\n",
        "    \"PC\": np.mean(pc_scores, axis=0),\n",
        "    \"Density\": np.mean(density_scores, axis=0),\n",
        "    \"PCE\": np.mean(pce_scores, axis=0),\n",
        "    \"RCE\": np.mean(rce_scores, axis=0),\n",
        "    \"RE\": np.mean(re_scores, axis=0),\n",
        "    \"FD\": np.mean(fd_scores, axis=0)\n",
        "}\n",
        "std_devs = {\n",
        "    \"Coverage\": np.std(coverage_scores, axis=0),\n",
        "    \"RC\": np.std(rc_scores, axis=0),\n",
        "    \"PC\": np.std(pc_scores, axis=0),\n",
        "    \"Density\": np.std(density_scores, axis=0),\n",
        "    \"PCE\": np.std(pce_scores, axis=0),\n",
        "    \"RCE\": np.std(rce_scores, axis=0),\n",
        "    \"RE\": np.std(re_scores, axis=0),\n",
        "    \"FD\": np.std(fd_scores, axis=0)\n",
        "}"
      ],
      "metadata": {
        "id": "wggUREGbbtY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for mode dropping experiment\n",
        "\n",
        "#models = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
        "models = [0, 1, 2, 3, 4]\n",
        "fig, axes = plt.subplots(2, 2, figsize=(11, 9))\n",
        "\n",
        "# Subplot 1\n",
        "ax1 = axes[0, 0]\n",
        "ax1.errorbar(models, means['Density'], yerr=std_devs['Density'], label='D', marker='x', markersize=10, color = 'mediumblue',  elinewidth=2, capthick=2, ecolor='gray')\n",
        "ax1.errorbar(models, means['Coverage'], yerr=std_devs['Coverage'], label='C', marker='D', markersize=7, color = 'orange',  elinewidth=2, capthick=2, ecolor='gray')\n",
        "ax1.set_xlabel('# of Modes Dropped')\n",
        "ax1.set_ylabel('Score')\n",
        "ax1.set_ylim(0, 1)\n",
        "ax1.set_xticks(models)\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.set_title('(a) Density and Coverage')\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2\n",
        "ax2 = axes[0, 1]\n",
        "ax2.errorbar(models, means['PC'], yerr=std_devs['PC'], label='PC', marker='x', markersize=10, color = 'mediumblue',  elinewidth=2, capthick=2, ecolor='gray')\n",
        "ax2.errorbar(models, means['RC'], yerr=std_devs['RC'], label='RC', marker='D', markersize=7, color = 'orange',  elinewidth=2, capthick=2, ecolor='gray')\n",
        "ax2.set_xlabel('# of Modes Dropped')\n",
        "ax2.set_ylabel('Score')\n",
        "ax2.set_ylim(0, 1)\n",
        "ax2.set_xticks(models)\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.set_title('(b) PC and RC')\n",
        "ax2.legend()\n",
        "\n",
        "# Subplot 3\n",
        "ax3 = axes[1, 0]\n",
        "ax3.errorbar(models, means['PCE'], yerr=std_devs['PCE'], label='PCE', marker='x', markersize=10, color = 'mediumblue',  elinewidth=2, capthick=2, ecolor='gray')\n",
        "ax3.errorbar(models, means['RCE'], yerr=std_devs['RCE'], label='RCE', marker='D', markersize=7, color = 'orange',  elinewidth=2, capthick=2, ecolor='gray')\n",
        "ax3.errorbar(models, means['RE'], yerr=std_devs['RE'], label='RE', marker='^', markersize=7, color = 'green',  elinewidth=2, capthick=2, ecolor='gray')\n",
        "ax3.set_xlabel('# of Modes Dropped')\n",
        "ax3.set_ylabel('Score')\n",
        "ax3.set_yticks(range(0, 601, 100))\n",
        "ax3.set_xticks(models)\n",
        "ax3.tick_params(axis='x', rotation=45)\n",
        "ax3.set_title('(c) PCE, RCE, and RE')\n",
        "ax3.legend(fontsize=19)\n",
        "\n",
        "# Subplot 4\n",
        "ax4 = axes[1, 1]\n",
        "ax4.errorbar(models, means['FD'], yerr=std_devs['FD'], label='FD', marker='x', markersize=10, color = 'mediumblue',  elinewidth=2, capthick=2, ecolor='gray')\n",
        "ax4.set_xlabel('# of Modes Dropped')\n",
        "ax4.set_ylabel('Score')\n",
        "ax4.set_yticks(range(0, 701, 100))\n",
        "ax4.set_xticks(models)\n",
        "ax4.tick_params(axis='x', rotation=45)\n",
        "ax4.set_title('(d) Fréchet Distance')\n",
        "ax4.legend(fontsize=26)\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C9sH2yxLbp4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Experiments"
      ],
      "metadata": {
        "id": "7YVr_Uyu4duY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Convergence"
      ],
      "metadata": {
        "id": "IC_ZT8zE-Ak9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric + sampling functions\n",
        "def generate_multid_gaussian_samples(mean, cov, num_samples):\n",
        "    return np.random.multivariate_normal(mean, cov, num_samples)\n",
        "\n",
        "# Optimized version of select metrics using KD trees\n",
        "\n",
        "def calc_density_kd(R, G, tree_G, k):\n",
        "    tree_R = KDTree(R)\n",
        "    dist_R, _ = tree_R.query(R, k=k+1)\n",
        "    radii_R = dist_R[:, -1]\n",
        "\n",
        "    density_counts = np.array([tree_G.query_radius([p], r, count_only=True) for p, r in zip(R, radii_R)])\n",
        "    overall_density = np.sum(density_counts) / (k * len(G))\n",
        "    return overall_density\n",
        "\n",
        "def calc_PC_kd(G, tree_G, tree_R, M, k, C):\n",
        "    k_prime = C * k\n",
        "    dist_G, ind_G = tree_G.query(G, k=k_prime+1)\n",
        "    radii_G = dist_G[:, -1]\n",
        "\n",
        "    points_in_radius = tree_R.query_radius(G, r=radii_G, count_only=True)\n",
        "\n",
        "    valid_balls = np.sum(points_in_radius >= k)\n",
        "\n",
        "    return valid_balls / M\n",
        "\n",
        "def calculate_realism_scores_kd(R, G, k=5, C=3):\n",
        "    # init KD-Trees\n",
        "    tree_R = KDTree(R)\n",
        "    tree_G = KDTree(G)\n",
        "\n",
        "    # compute metrics\n",
        "    density = calc_density_kd(R, G, tree_G, k)\n",
        "    pc = calc_PC_kd(G, tree_G, tree_R, len(G), k, C)\n",
        "\n",
        "    print(f\"Density: {density}\")\n",
        "    print(f\"Precision Coverage (PC): {pc}\")\n",
        "\n",
        "    return density, pc\n"
      ],
      "metadata": {
        "id": "YM9U6QNc-Dfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the behavior of density and precision coverage for two different distributions\n",
        "\n",
        "mean_R = [0, 0]\n",
        "mean_G = [2, 2]\n",
        "cov_R = np.array([[1, 0.1], [0.1, 1]])\n",
        "cov_G = np.array([[1, 0.1], [0.1, 1]])\n",
        "k = 25\n",
        "sample_sizes = np.linspace(10000, 1500000, num=30).astype(int)\n",
        "\n",
        "density = []\n",
        "pc = []\n",
        "\n",
        "for num_samples in sample_sizes:\n",
        "    R = generate_multid_gaussian_samples(mean_R, cov_R, num_samples)\n",
        "    G = generate_multid_gaussian_samples(mean_G, cov_G, num_samples)\n",
        "    print(G.shape)\n",
        "    density_i, pc_i = calculate_realism_scores_kd(R, G, k)\n",
        "    density.append(density_i)\n",
        "    pc.append(pc_i)"
      ],
      "metadata": {
        "id": "Hy7FF-D9-wsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot sample experiment\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(sample_sizes, density, 'r-o', label='Density')\n",
        "plt.plot(sample_sizes, pc, 'b-o', label='PC')\n",
        "plt.axhline(y=1, color='gray', linestyle='--')  # dashed line at y=1\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('Metric Values')\n",
        "plt.title('Density and PC Over Increasing Sample Sizes')\n",
        "plt.legend()\n",
        "plt.ylim(0, 1.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TX2HQwMO_yOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D visualization of distributions\n",
        "\n",
        "N_R = 500\n",
        "N_G = 500\n",
        "\n",
        "R = np.random.multivariate_normal(mean_R, cov_R, N_R)\n",
        "G = np.random.multivariate_normal(mean_G, cov_G, N_G)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(R[:, 0], R[:, 1], color='green', alpha=0.5, label='R')\n",
        "plt.scatter(G[:, 0], G[:, 1], color='hotpink', alpha=0.5, label='G')\n",
        "\n",
        "\n",
        "plt.title('2D Visualization of R and G')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gK37mcUD_TKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memorization"
      ],
      "metadata": {
        "id": "kO_6Tm-nKg_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we perform our sample-level memorization experiment; note because of the limited sample set, the points printed are not what, from the full dataset, we would consider memorized."
      ],
      "metadata": {
        "id": "3OJuJKPaZVdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate sample-level contribution to PCE score\n",
        "def cross_entropy_sample(N, M, k, nu_k, d):\n",
        "    psi_k = digamma(k)\n",
        "\n",
        "    c_bar = volume_of_unit_ball_log(d)\n",
        "\n",
        "    inner_term = np.log(M) - psi_k + c_bar + d*np.log(nu_k)\n",
        "    entropy_estimate = (1 / N) * np.sum(inner_term)\n",
        "\n",
        "    return inner_term\n",
        "\n",
        "def entropy_sample(N, k, rho_k, d):\n",
        "    psi_k = digamma(k)\n",
        "\n",
        "    c_bar = volume_of_unit_ball_log(d)\n",
        "\n",
        "    inner_term = np.log(N-1) - psi_k + c_bar + d*np.log(rho_k)\n",
        "    entropy_estimate = (1 / N) * np.sum(inner_term)\n",
        "\n",
        "    return inner_term\n",
        "\n",
        "def calculate_pce_scores(R, G, ce_k = 1):\n",
        "\n",
        "    nbrs_R = NearestNeighbors(n_neighbors=ce_k+1, algorithm='auto', n_jobs=-1).fit(R) # ignore first neighbor (itself)\n",
        "    dist_R, _ = nbrs_R.kneighbors(R, ce_k+1)\n",
        "\n",
        "    nbrs_G = NearestNeighbors(n_neighbors=ce_k+1, algorithm='auto', n_jobs=-1).fit(G)\n",
        "    dist_G, _ = nbrs_G.kneighbors(G, ce_k+1)\n",
        "\n",
        "    dist_RG_pairs = pairwise_distances(R, G, n_jobs=-1)\n",
        "    dist_GR_pairs = pairwise_distances(G, R, n_jobs=-1)\n",
        "\n",
        "    dist_RG, _ = nbrs_G.kneighbors(R, ce_k+1)\n",
        "    dist_GR, ind = nbrs_R.kneighbors(G, ce_k+1)\n",
        "\n",
        "    ce_gr = cross_entropy_sample(len(G), len(R), ce_k, dist_GR[:, ce_k-1], len(R[0]))\n",
        "    e_r = entropy_sample(len(R), ce_k, dist_R[:, ce_k], len(R[0]))\n",
        "\n",
        "    return ce_gr-e_r, ind"
      ],
      "metadata": {
        "id": "09w5813kKkBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate PCE for samples of LOGAN\n",
        "scores_PCE = []\n",
        "PCE_ind = []\n",
        "\n",
        "real_features = np.load('output/cifar10-train_features.npy')\n",
        "model_features = {'LOGAN': np.load('output/cifar10-LOGAN_features.npy')}\n",
        "\n",
        "for model_name, features in model_features.items():\n",
        "    print(model_name)\n",
        "    pce, pce_ind = calculate_pce_scores(real_features, features, 1)\n",
        "    scores_PCE = pce\n",
        "    PCE_ind = pce_ind[:, 0]\n",
        "    print(\"done\")\n",
        "\n",
        "# combine the indices of images with scores\n",
        "indexed_scores = list(zip(scores_PCE, range(scores_PCE.shape[0])))\n",
        "# sort by scores\n",
        "indexed_scores.sort(key=lambda x: x[0], reverse=False)"
      ],
      "metadata": {
        "id": "gQhR-wgeZlh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated images alongside their nearest real neighbor\n",
        "def display_images_in_batches(indexed_scores, gen_dataset, real_dataset, qp_ind, batch_size=5):\n",
        "    num_batches = len(indexed_scores) // batch_size\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        plt.figure(figsize=(25, 10))  # 5 images per row, 2 rows a set\n",
        "        gen_paths = []\n",
        "        real_paths = []\n",
        "        titles = []\n",
        "        scores = []\n",
        "\n",
        "        for score, ind in indexed_scores[batch * batch_size : (batch + 1) * batch_size]:\n",
        "            gen_path, gen_label = gen_dataset.samples[ind]\n",
        "            real_path, real_label = real_dataset.samples[qp_ind[ind]]\n",
        "\n",
        "            gen_paths.append(gen_path)\n",
        "            real_paths.append(real_path)\n",
        "            titles.append(gen_dataset.classes[gen_label])\n",
        "            scores.append(score)\n",
        "\n",
        "        # display generated images with scores\n",
        "        for i in range(batch_size):\n",
        "            plt.subplot(2, batch_size, i + 1)\n",
        "            image = Image.open(gen_paths[i])\n",
        "            plt.imshow(image)\n",
        "            plt.title(f\"PCE: {scores[i]:.2f}\", fontsize=40)\n",
        "            plt.axis('off')\n",
        "\n",
        "        # Ddsplay real images\n",
        "        for i in range(batch_size):\n",
        "            plt.subplot(2, batch_size, batch_size + i + 1)\n",
        "            image = Image.open(real_paths[i])\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Usage:\n",
        "gen_dataset = ImageFolder('images/cifar10-LOGAN', transform=transform)\n",
        "real_dataset = ImageFolder('images/cifar10-train', transform=transform)\n",
        "display_images_in_batches(indexed_scores, gen_dataset, real_dataset, PCE_ind, batch_size=5)\n"
      ],
      "metadata": {
        "id": "Rwfd5hgfaSVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}